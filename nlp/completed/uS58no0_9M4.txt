{"text":"{|4920|#|/n/ /st/The real world/ |}{|20700|#|/n/ /st/No training data? Manually written rules/ |}{|33700|#|/n/Need careful crafting|}{|40220|#|/n/-time consuming|}{|52960|#|/n/ /st/Very little data?/ |}{|59460|#|/n/Use Naive Bayes|}{|67480|#|/n/A high bias algorithm|}{|80640|#|/n/Get more labeled data|}{|88400|#|/n/Try semi-supervised training methods|}{|107160|#|/n/ /st/A reasonable amount of data?/ |}{|114400|#|/n/Perfect for all the clever classifiers|}{|123160|#|/n/User interpretable Decision trees|}{|146257|#|/n/ /st/A huge amount of data/ |}{|157257|#|/n/High accuracy|}{|161257|#|/n/At a cost - maybe too slow|}{|169757|#|/n/ /st/Accuracy as a function of data size/ |}{|185017|#|/n/If there is a really huge amount of data, the classifier may not even matter|}{|217517|#|/n/ /st/Real world systems generally combine/ |}{|227057|#|/n/Automatic classification|}{|232057|#|/n/Manual review|}{|235797|#|/n/ /st/Underflow prevention: log space/ |}{|244337|#|/n/Multiplying lots of probabilities can result in floating point underflow|}{|283377|#|/n/Model is now just max of sum of weights|}{|292637|#|/n/ /st/How to tweak performance/ |}{|298877|#|/n/Domain specific features and weights|}{|307457|#|/n/Sometimes we need to collapse terms|}{|323717|#|/n/But stemming generally doesn't help|}{|330477|#|/n/Upweighting: counting a word as if it occured twice|}","css":".st{font-weight:bold;}\n.st:before{\n    content:\"\\000A\";\n    white-space: pre;\n}","videoid":"uS58no0_9M4","title":"6 - 9 - Practical Issues in Text Classification - Stanford NLP-Dan Jurafsky & Chris Manning","duration":356.773967}