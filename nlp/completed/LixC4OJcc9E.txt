{"text":"{|9920|#|/n/ /st/Feature based linear classifiers/ |}{|19940|#|/n/Set of features|}{|26440|#|/n/Calculate a linear function of those features|}{|53360|#|/n/What features  match against datum?|}{|68100|#|/n/Example|}{|193640|#|/n/Choose the class that has the highest total vote|}{|239400|#|/n//n/Many ways to choose weights for features|}{|258200|#|/n/Perceptron and support vector machines|}{|270440|#|/n//n/Exponential models|}{|564960|#|/n//n/The weights are the parameters of the probability model, combined via a \"soft max\" function|}{|607720|#|/n//n/Given this model form, we will choose parameters that will maximize the conditional likelihood of the data according to this model|}{|643500|#|/n/We construct not only classification, but probability distributions over classifications|}{|669000|#|/n/ /st/Aside: logistic regression/ |}{|704000|#|/n/The parameterization is slightly different in a way that is advantageous for NLP-style models with tons of sparse features|}{|740040|#|/n/Feature functions|}","css":".st{font-weight:bold;}\n.st:before{\n    content:\"\\000A\";\n    white-space: pre;\n}","videoid":"LixC4OJcc9E","title":"8 - 3 - Feature-Based Linear Classifiers - Stanford NLP - Professor Dan Jurafsky & Chris Manning","duration":814.811427}