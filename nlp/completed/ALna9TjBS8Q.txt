{"text":"{|4921|#|/n/ /st/Generative model for multinomial naive bayes/ |}{|18701|#|/n/Randomly generating document about China|}{|43001|#|/n/Each word is an independently generated word with certain probability|}{|57521|#|/n/ /st/Naive Bayes and Language Modeling/ |}{|66581|#|/n/NB can use any sort of feature|}{|75601|#|/n/ /st/Each class = a unigram language model/ |}{|103063|#|/n/Assigning each word: P(word | c)|}{|111063|#|/n/Assigning each sentence|}{|183643|#|/n/ /st/Naive bayes as a language model/ |}{|192903|#|/n/Which class assigns the higher probability to s?|}{|242203|#|/n/Pos &gt; neg probability in this case|}","css":".st{font-weight:bold;}\n.st:before{\n    content:\"\\000A\";\n    white-space: pre;\n}","videoid":"ALna9TjBS8Q","title":"6-5-Naive Bayes_ Relationship to Language Modeling-Stanford NLP-Dan Jurafsky & Chris Manning","duration":275.829273}